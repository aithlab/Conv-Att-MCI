{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch import optim\n",
    "from collections import deque\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import Conv_Att_MCI_Dataset\n",
    "from models import BaseModel, VGG16GradCAM, ConvAttnModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "SEED = 1234\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "img_type = 'all'\n",
    "\n",
    "# Model\n",
    "backbone_freezing = True\n",
    "## Conv-Att\n",
    "h_dim_attn = 128\n",
    "n_heads = 1\n",
    "h_dim_fc = 512\n",
    "n_layers = 1\n",
    "\n",
    "# training\n",
    "batch_size = 32#64\n",
    "n_epochs = 100\n",
    "\n",
    "# optimizer\n",
    "lr = 1e-5\n",
    "beta_1 = 0.9\n",
    "beta_2 = 0.99\n",
    "eps = 1e-7\n",
    "\n",
    "## Early stopping\n",
    "es_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Conv_Att_MCI_Dataset(img_type)\n",
    "dataset_trn, dataset_val, dataset_test = dataset.split_trn_val_test()\n",
    "dataloader_trn = DataLoader(dataset_trn, batch_size=batch_size, shuffle=True)\n",
    "dataloader_val = DataLoader(dataset_val, batch_size=batch_size, shuffle=True)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/cdt/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/envs/cdt/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/root/miniconda3/envs/cdt/lib/python3.8/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "# model = BaseModel(img_type, backbone_freezing).to(device)\n",
    "# model = VGG16GradCAM(img_type, backbone_freezing).to(device)\n",
    "model = ConvAttnModel(img_type, h_dim_attn, n_heads, h_dim_fc, n_layers, backbone_freezing).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr, [beta_1, beta_2], eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch 1/100 |\n",
      "| Train      | Loss   0.70 | Acc.   0.64 |\n",
      "| Validation | Loss   0.67 | Acc.   0.71 |\n",
      "| Test       | Loss   0.68 | Acc.   0.69 |\n",
      "| Epoch 2/100 |\n",
      "| Train      | Loss   0.65 | Acc.   0.70 |\n",
      "| Validation | Loss   0.64 | Acc.   0.71 |\n",
      "| Test       | Loss   0.64 | Acc.   0.77 |\n",
      "| Epoch 3/100 |\n",
      "| Train      | Loss   0.61 | Acc.   0.73 |\n",
      "| Validation | Loss   0.60 | Acc.   0.70 |\n",
      "| Test       | Loss   0.65 | Acc.   0.65 |\n",
      "| Epoch 4/100 |\n",
      "| Train      | Loss   0.59 | Acc.   0.76 |\n",
      "| Validation | Loss   0.60 | Acc.   0.75 |\n",
      "| Test       | Loss   0.62 | Acc.   0.75 |\n",
      "| Epoch 5/100 |\n",
      "| Train      | Loss   0.57 | Acc.   0.76 |\n",
      "| Validation | Loss   0.59 | Acc.   0.70 |\n",
      "| Test       | Loss   0.60 | Acc.   0.73 |\n",
      "| Epoch 6/100 |\n",
      "| Train      | Loss   0.57 | Acc.   0.77 |\n",
      "| Validation | Loss   0.59 | Acc.   0.70 |\n",
      "| Test       | Loss   0.58 | Acc.   0.75 |\n",
      "| Epoch 7/100 |\n",
      "| Train      | Loss   0.56 | Acc.   0.76 |\n",
      "| Validation | Loss   0.57 | Acc.   0.73 |\n",
      "| Test       | Loss   0.57 | Acc.   0.76 |\n",
      "| Epoch 8/100 |\n",
      "| Train      | Loss   0.55 | Acc.   0.78 |\n",
      "| Validation | Loss   0.56 | Acc.   0.79 |\n",
      "| Test       | Loss   0.57 | Acc.   0.76 |\n",
      "| Epoch 9/100 |\n",
      "| Train      | Loss   0.54 | Acc.   0.79 |\n",
      "| Validation | Loss   0.58 | Acc.   0.77 |\n",
      "| Test       | Loss   0.58 | Acc.   0.76 |\n",
      "| Epoch 10/100 |\n",
      "| Train      | Loss   0.53 | Acc.   0.79 |\n",
      "| Validation | Loss   0.60 | Acc.   0.76 |\n",
      "| Test       | Loss   0.58 | Acc.   0.77 |\n",
      "| Epoch 11/100 |\n",
      "| Train      | Loss   0.53 | Acc.   0.81 |\n",
      "| Validation | Loss   0.55 | Acc.   0.75 |\n",
      "| Test       | Loss   0.55 | Acc.   0.79 |\n",
      "| Epoch 12/100 |\n",
      "| Train      | Loss   0.52 | Acc.   0.80 |\n",
      "| Validation | Loss   0.54 | Acc.   0.77 |\n",
      "| Test       | Loss   0.56 | Acc.   0.74 |\n",
      "| Epoch 13/100 |\n",
      "| Train      | Loss   0.51 | Acc.   0.79 |\n",
      "| Validation | Loss   0.61 | Acc.   0.76 |\n",
      "| Test       | Loss   0.59 | Acc.   0.76 |\n",
      "| Epoch 14/100 |\n",
      "| Train      | Loss   0.51 | Acc.   0.82 |\n",
      "| Validation | Loss   0.55 | Acc.   0.78 |\n",
      "| Test       | Loss   0.55 | Acc.   0.81 |\n",
      "| Epoch 15/100 |\n",
      "| Train      | Loss   0.50 | Acc.   0.82 |\n",
      "| Validation | Loss   0.56 | Acc.   0.76 |\n",
      "| Test       | Loss   0.57 | Acc.   0.79 |\n",
      "| Epoch 16/100 |\n",
      "| Train      | Loss   0.49 | Acc.   0.82 |\n",
      "| Validation | Loss   0.55 | Acc.   0.77 |\n",
      "| Test       | Loss   0.55 | Acc.   0.80 |\n",
      "| Epoch 17/100 |\n",
      "| Train      | Loss   0.49 | Acc.   0.83 |\n",
      "| Validation | Loss   0.58 | Acc.   0.76 |\n",
      "| Test       | Loss   0.54 | Acc.   0.78 |\n",
      "| Epoch 18/100 |\n",
      "| Train      | Loss   0.47 | Acc.   0.85 |\n",
      "| Validation | Loss   0.57 | Acc.   0.75 |\n",
      "| Test       | Loss   0.56 | Acc.   0.81 |\n",
      "| Epoch 19/100 |\n",
      "| Train      | Loss   0.46 | Acc.   0.86 |\n",
      "| Validation | Loss   0.56 | Acc.   0.76 |\n",
      "| Test       | Loss   0.54 | Acc.   0.78 |\n",
      "| Epoch 20/100 |\n",
      "| Train      | Loss   0.45 | Acc.   0.86 |\n",
      "| Validation | Loss   0.59 | Acc.   0.78 |\n",
      "| Test       | Loss   0.56 | Acc.   0.79 |\n",
      "| Epoch 21/100 |\n",
      "| Train      | Loss   0.44 | Acc.   0.87 |\n",
      "| Validation | Loss   0.57 | Acc.   0.74 |\n",
      "| Test       | Loss   0.53 | Acc.   0.79 |\n",
      "| Epoch 22/100 |\n",
      "| Train      | Loss   0.45 | Acc.   0.86 |\n",
      "| Validation | Loss   0.59 | Acc.   0.77 |\n",
      "| Test       | Loss   0.60 | Acc.   0.76 |\n",
      "| Epoch 23/100 |\n",
      "| Train      | Loss   0.43 | Acc.   0.88 |\n",
      "| Validation | Loss   0.57 | Acc.   0.74 |\n",
      "| Test       | Loss   0.54 | Acc.   0.76 |\n",
      "| Epoch 24/100 |\n",
      "| Train      | Loss   0.43 | Acc.   0.88 |\n",
      "| Validation | Loss   0.60 | Acc.   0.78 |\n",
      "| Test       | Loss   0.58 | Acc.   0.79 |\n",
      "| Epoch 25/100 |\n",
      "| Train      | Loss   0.42 | Acc.   0.90 |\n",
      "| Validation | Loss   0.54 | Acc.   0.78 |\n",
      "| Test       | Loss   0.57 | Acc.   0.78 |\n",
      "| Epoch 26/100 |\n",
      "| Train      | Loss   0.41 | Acc.   0.89 |\n",
      "| Validation | Loss   0.56 | Acc.   0.77 |\n",
      "| Test       | Loss   0.53 | Acc.   0.79 |\n",
      "| Epoch 27/100 |\n",
      "| Train      | Loss   0.40 | Acc.   0.90 |\n",
      "| Validation | Loss   0.61 | Acc.   0.77 |\n",
      "| Test       | Loss   0.58 | Acc.   0.79 |\n",
      "| Epoch 28/100 |\n",
      "| Train      | Loss   0.39 | Acc.   0.92 |\n",
      "| Validation | Loss   0.60 | Acc.   0.78 |\n",
      "| Test       | Loss   0.60 | Acc.   0.77 |\n",
      "| Epoch 29/100 |\n",
      "| Train      | Loss   0.40 | Acc.   0.91 |\n",
      "| Validation | Loss   0.57 | Acc.   0.77 |\n",
      "| Test       | Loss   0.57 | Acc.   0.77 |\n",
      "| Epoch 30/100 |\n",
      "| Train      | Loss   0.39 | Acc.   0.92 |\n",
      "| Validation | Loss   0.60 | Acc.   0.77 |\n",
      "| Test       | Loss   0.58 | Acc.   0.79 |\n",
      "| Epoch 31/100 |\n",
      "| Train      | Loss   0.38 | Acc.   0.92 |\n",
      "| Validation | Loss   0.58 | Acc.   0.79 |\n",
      "| Test       | Loss   0.56 | Acc.   0.82 |\n",
      "| Epoch 32/100 |\n",
      "| Train      | Loss   0.38 | Acc.   0.92 |\n",
      "| Validation | Loss   0.56 | Acc.   0.78 |\n",
      "| Test       | Loss   0.57 | Acc.   0.77 |\n",
      "| Epoch 33/100 |\n",
      "| Train      | Loss   0.37 | Acc.   0.93 |\n",
      "| Validation | Loss   0.55 | Acc.   0.76 |\n",
      "| Test       | Loss   0.57 | Acc.   0.75 |\n",
      "| Epoch 34/100 |\n",
      "| Train      | Loss   0.37 | Acc.   0.93 |\n",
      "| Validation | Loss   0.61 | Acc.   0.76 |\n",
      "| Test       | Loss   0.56 | Acc.   0.80 |\n",
      "| Epoch 35/100 |\n",
      "| Train      | Loss   0.36 | Acc.   0.93 |\n",
      "| Validation | Loss   0.60 | Acc.   0.78 |\n",
      "| Test       | Loss   0.58 | Acc.   0.76 |\n",
      "| Epoch 36/100 |\n",
      "| Train      | Loss   0.36 | Acc.   0.94 |\n",
      "| Validation | Loss   0.58 | Acc.   0.79 |\n",
      "| Test       | Loss   0.59 | Acc.   0.78 |\n",
      "| Epoch 37/100 |\n",
      "| Train      | Loss   0.36 | Acc.   0.93 |\n",
      "| Validation | Loss   0.59 | Acc.   0.76 |\n",
      "| Test       | Loss   0.55 | Acc.   0.80 |\n",
      "| Epoch 38/100 |\n",
      "| Train      | Loss   0.36 | Acc.   0.94 |\n",
      "| Validation | Loss   0.57 | Acc.   0.76 |\n",
      "| Test       | Loss   0.58 | Acc.   0.76 |\n",
      "| Epoch 39/100 |\n",
      "| Train      | Loss   0.35 | Acc.   0.95 |\n",
      "| Validation | Loss   0.59 | Acc.   0.73 |\n",
      "| Test       | Loss   0.55 | Acc.   0.79 |\n",
      "| Epoch 40/100 |\n",
      "| Train      | Loss   0.36 | Acc.   0.94 |\n",
      "| Validation | Loss   0.58 | Acc.   0.77 |\n",
      "| Test       | Loss   0.55 | Acc.   0.80 |\n",
      "| Epoch 41/100 |\n",
      "| Train      | Loss   0.35 | Acc.   0.95 |\n",
      "| Validation | Loss   0.62 | Acc.   0.77 |\n",
      "| Test       | Loss   0.59 | Acc.   0.77 |\n",
      "| Epoch 42/100 |\n",
      "| Train      | Loss   0.35 | Acc.   0.96 |\n",
      "| Validation | Loss   0.57 | Acc.   0.77 |\n",
      "| Test       | Loss   0.55 | Acc.   0.78 |\n",
      "| Epoch 43/100 |\n",
      "| Train      | Loss   0.35 | Acc.   0.95 |\n",
      "| Validation | Loss   0.60 | Acc.   0.77 |\n",
      "| Test       | Loss   0.56 | Acc.   0.79 |\n",
      "| Epoch 44/100 |\n",
      "| Train      | Loss   0.35 | Acc.   0.95 |\n",
      "| Validation | Loss   0.57 | Acc.   0.79 |\n",
      "| Test       | Loss   0.57 | Acc.   0.79 |\n",
      "| Epoch 45/100 |\n",
      "| Train      | Loss   0.34 | Acc.   0.95 |\n",
      "| Validation | Loss   0.62 | Acc.   0.75 |\n",
      "| Test       | Loss   0.55 | Acc.   0.80 |\n",
      "| Epoch 46/100 |\n",
      "| Train      | Loss   0.35 | Acc.   0.96 |\n",
      "| Validation | Loss   0.59 | Acc.   0.76 |\n",
      "| Test       | Loss   0.58 | Acc.   0.79 |\n",
      "| Epoch 47/100 |\n",
      "| Train      | Loss   0.34 | Acc.   0.96 |\n",
      "| Validation | Loss   0.57 | Acc.   0.76 |\n",
      "| Test       | Loss   0.53 | Acc.   0.80 |\n",
      "| Epoch 48/100 |\n",
      "| Train      | Loss   0.34 | Acc.   0.95 |\n",
      "| Validation | Loss   0.57 | Acc.   0.79 |\n",
      "| Test       | Loss   0.58 | Acc.   0.81 |\n",
      "| Epoch 49/100 |\n",
      "| Train      | Loss   0.34 | Acc.   0.94 |\n",
      "| Validation | Loss   0.58 | Acc.   0.76 |\n",
      "| Test       | Loss   0.58 | Acc.   0.77 |\n",
      "| Epoch 50/100 |\n",
      "| Train      | Loss   0.34 | Acc.   0.95 |\n",
      "| Validation | Loss   0.60 | Acc.   0.76 |\n",
      "| Test       | Loss   0.57 | Acc.   0.79 |\n",
      "| Epoch 51/100 |\n",
      "| Train      | Loss   0.33 | Acc.   0.96 |\n",
      "| Validation | Loss   0.59 | Acc.   0.78 |\n",
      "| Test       | Loss   0.61 | Acc.   0.78 |\n",
      "| Epoch 52/100 |\n",
      "| Train      | Loss   0.33 | Acc.   0.96 |\n",
      "| Validation | Loss   0.58 | Acc.   0.76 |\n",
      "| Test       | Loss   0.56 | Acc.   0.77 |\n",
      "| Epoch 53/100 |\n",
      "| Train      | Loss   0.34 | Acc.   0.95 |\n",
      "| Validation | Loss   0.59 | Acc.   0.76 |\n",
      "| Test       | Loss   0.55 | Acc.   0.79 |\n",
      "| Epoch 54/100 |\n",
      "| Train      | Loss   0.33 | Acc.   0.96 |\n",
      "| Validation | Loss   0.58 | Acc.   0.76 |\n",
      "| Test       | Loss   0.56 | Acc.   0.79 |\n",
      "| Epoch 55/100 |\n",
      "| Train      | Loss   0.33 | Acc.   0.95 |\n",
      "| Validation | Loss   0.60 | Acc.   0.78 |\n",
      "| Test       | Loss   0.57 | Acc.   0.80 |\n",
      "| Epoch 56/100 |\n",
      "| Train      | Loss   0.33 | Acc.   0.96 |\n",
      "| Validation | Loss   0.58 | Acc.   0.79 |\n",
      "| Test       | Loss   0.56 | Acc.   0.79 |\n",
      "| Epoch 57/100 |\n",
      "| Train      | Loss   0.33 | Acc.   0.96 |\n",
      "| Validation | Loss   0.64 | Acc.   0.76 |\n",
      "| Test       | Loss   0.61 | Acc.   0.78 |\n",
      "| Epoch 58/100 |\n",
      "| Train      | Loss   0.33 | Acc.   0.95 |\n",
      "| Validation | Loss   0.57 | Acc.   0.77 |\n",
      "| Test       | Loss   0.57 | Acc.   0.76 |\n",
      "| Epoch 59/100 |\n",
      "| Train      | Loss   0.33 | Acc.   0.95 |\n",
      "| Validation | Loss   0.58 | Acc.   0.79 |\n",
      "| Test       | Loss   0.57 | Acc.   0.75 |\n",
      "| Epoch 60/100 |\n",
      "| Train      | Loss   0.32 | Acc.   0.96 |\n",
      "| Validation | Loss   0.55 | Acc.   0.80 |\n",
      "| Test       | Loss   0.56 | Acc.   0.74 |\n",
      "| Epoch 61/100 |\n",
      "| Train      | Loss   0.33 | Acc.   0.96 |\n",
      "| Validation | Loss   0.60 | Acc.   0.77 |\n",
      "| Test       | Loss   0.54 | Acc.   0.80 |\n",
      "| Epoch 62/100 |\n",
      "| Train      | Loss   0.32 | Acc.   0.96 |\n",
      "| Validation | Loss   0.58 | Acc.   0.80 |\n",
      "| Test       | Loss   0.56 | Acc.   0.79 |\n",
      "| Epoch 63/100 |\n",
      "| Train      | Loss   0.32 | Acc.   0.97 |\n",
      "| Validation | Loss   0.59 | Acc.   0.78 |\n",
      "| Test       | Loss   0.58 | Acc.   0.78 |\n",
      "| Epoch 64/100 |\n",
      "| Train      | Loss   0.32 | Acc.   0.95 |\n",
      "| Validation | Loss   0.59 | Acc.   0.75 |\n",
      "| Test       | Loss   0.57 | Acc.   0.80 |\n",
      "| Epoch 65/100 |\n",
      "| Train      | Loss   0.32 | Acc.   0.96 |\n",
      "| Validation | Loss   0.58 | Acc.   0.75 |\n",
      "| Test       | Loss   0.54 | Acc.   0.79 |\n",
      "| Epoch 66/100 |\n",
      "| Train      | Loss   0.32 | Acc.   0.97 |\n",
      "| Validation | Loss   0.59 | Acc.   0.79 |\n",
      "| Test       | Loss   0.56 | Acc.   0.79 |\n",
      "| Epoch 67/100 |\n",
      "| Train      | Loss   0.32 | Acc.   0.96 |\n",
      "| Validation | Loss   0.58 | Acc.   0.75 |\n",
      "| Test       | Loss   0.55 | Acc.   0.80 |\n",
      "| Epoch 68/100 |\n",
      "| Train      | Loss   0.32 | Acc.   0.95 |\n",
      "| Validation | Loss   0.60 | Acc.   0.77 |\n",
      "| Test       | Loss   0.60 | Acc.   0.78 |\n",
      "| Epoch 69/100 |\n",
      "| Train      | Loss   0.32 | Acc.   0.95 |\n",
      "| Validation | Loss   0.59 | Acc.   0.77 |\n",
      "| Test       | Loss   0.56 | Acc.   0.80 |\n",
      "| Epoch 70/100 |\n",
      "| Train      | Loss   0.32 | Acc.   0.97 |\n",
      "| Validation | Loss   0.57 | Acc.   0.78 |\n",
      "| Test       | Loss   0.55 | Acc.   0.80 |\n",
      "| Epoch 71/100 |\n",
      "| Train      | Loss   0.32 | Acc.   0.97 |\n",
      "| Validation | Loss   0.58 | Acc.   0.76 |\n",
      "| Test       | Loss   0.56 | Acc.   0.77 |\n",
      "| Epoch 72/100 |\n",
      "| Train      | Loss   0.32 | Acc.   0.96 |\n",
      "| Validation | Loss   0.58 | Acc.   0.77 |\n",
      "| Test       | Loss   0.55 | Acc.   0.79 |\n",
      "| Epoch 73/100 |\n",
      "| Train      | Loss   0.32 | Acc.   0.97 |\n",
      "| Validation | Loss   0.65 | Acc.   0.78 |\n",
      "| Test       | Loss   0.63 | Acc.   0.77 |\n",
      "| Epoch 74/100 |\n",
      "| Train      | Loss   0.33 | Acc.   0.95 |\n",
      "| Validation | Loss   0.57 | Acc.   0.80 |\n",
      "| Test       | Loss   0.56 | Acc.   0.77 |\n",
      "| Epoch 75/100 |\n",
      "| Train      | Loss   0.32 | Acc.   0.97 |\n",
      "| Validation | Loss   0.59 | Acc.   0.77 |\n",
      "| Test       | Loss   0.55 | Acc.   0.80 |\n",
      "| Epoch 76/100 |\n",
      "| Train      | Loss   0.32 | Acc.   0.97 |\n",
      "| Validation | Loss   0.56 | Acc.   0.78 |\n",
      "| Test       | Loss   0.56 | Acc.   0.79 |\n",
      "| Epoch 77/100 |\n",
      "| Train      | Loss   0.32 | Acc.   0.96 |\n",
      "| Validation | Loss   0.57 | Acc.   0.76 |\n",
      "| Test       | Loss   0.54 | Acc.   0.75 |\n",
      "| Epoch 78/100 |\n",
      "| Train      | Loss   0.32 | Acc.   0.97 |\n",
      "| Validation | Loss   0.62 | Acc.   0.77 |\n",
      "| Test       | Loss   0.60 | Acc.   0.80 |\n",
      "| Epoch 79/100 |\n",
      "| Train      | Loss   0.32 | Acc.   0.97 |\n",
      "| Validation | Loss   0.61 | Acc.   0.77 |\n",
      "| Test       | Loss   0.56 | Acc.   0.78 |\n",
      "| Epoch 80/100 |\n",
      "| Train      | Loss   0.32 | Acc.   0.96 |\n",
      "| Validation | Loss   0.56 | Acc.   0.80 |\n",
      "| Test       | Loss   0.54 | Acc.   0.78 |\n",
      "| Epoch 81/100 |\n",
      "| Train      | Loss   0.31 | Acc.   0.97 |\n",
      "| Validation | Loss   0.57 | Acc.   0.80 |\n",
      "| Test       | Loss   0.55 | Acc.   0.79 |\n",
      "| Epoch 82/100 |\n",
      "| Train      | Loss   0.31 | Acc.   0.97 |\n",
      "| Validation | Loss   0.60 | Acc.   0.77 |\n",
      "| Test       | Loss   0.55 | Acc.   0.77 |\n"
     ]
    }
   ],
   "source": [
    "results = {\n",
    "    'losses':{'trn':[], 'val':[], 'test':[]},\n",
    "    'corrects':{'trn':[], 'val':[], 'test':[]},\n",
    "    'accs':{'trn':[], 'val':[], 'test':[]},\n",
    "}\n",
    "es_queue, es_flag = deque(maxlen=es_size), False\n",
    "for epoch in range(n_epochs):\n",
    "    _losses, _corrects, n_tot = [],[],0\n",
    "    model.train()\n",
    "    for x, y, info in dataloader_trn:\n",
    "        for i in range(len(x)):\n",
    "            x[i] = x[i].to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        y_pred = model(x)\n",
    "        y_prob = y_pred.softmax(-1)[:,1]\n",
    "        loss = F.binary_cross_entropy(y_prob, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _correct = ((y_prob.cpu() >= 0.5) == info['labels']).sum()\n",
    "\n",
    "        _losses.append(loss.item())\n",
    "        _corrects.append(_correct)\n",
    "        n_tot += len(x[-1])\n",
    "    \n",
    "    accs = sum(_corrects) / n_tot\n",
    "    results['losses']['trn'].append(np.mean(_losses))\n",
    "    results['corrects']['trn'].append(sum(_corrects))\n",
    "    results['accs']['trn'].append(accs)\n",
    "\n",
    "    _losses, _corrects, n_tot = [],[],0\n",
    "    model.eval()\n",
    "    for x, y, info in dataloader_val:\n",
    "        for i in range(len(x)):\n",
    "            x[i] = x[i].to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        y_pred = model(x)\n",
    "        y_prob = y_pred.softmax(-1)[:,1]\n",
    "        loss = F.binary_cross_entropy(y_prob, y)\n",
    "\n",
    "        _correct = ((y_prob.cpu() >= 0.5) == info['labels']).sum()\n",
    "\n",
    "        _losses.append(loss.item())\n",
    "        _corrects.append(_correct)\n",
    "        n_tot += len(x[-1])\n",
    "    \n",
    "    accs = sum(_corrects) / n_tot\n",
    "    results['losses']['val'].append(np.mean(_losses))\n",
    "    results['corrects']['val'].append(sum(_corrects))\n",
    "    results['accs']['val'].append(accs)\n",
    "\n",
    "    _losses, _corrects, n_tot = [],[],0\n",
    "    model.eval()\n",
    "    for x, y, info in dataloader_test:\n",
    "        for i in range(len(x)):\n",
    "            x[i] = x[i].to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        y_pred = model(x)\n",
    "        y_prob = y_pred.softmax(-1)[:,1]\n",
    "        loss = F.binary_cross_entropy(y_prob, y)\n",
    "\n",
    "        _correct = ((y_prob.cpu() >= 0.5) == info['labels']).sum()\n",
    "\n",
    "        _losses.append(loss.item())\n",
    "        _corrects.append(_correct)\n",
    "        n_tot += len(x[-1])\n",
    "    \n",
    "    accs = sum(_corrects) / n_tot\n",
    "    results['losses']['test'].append(np.mean(_losses))\n",
    "    results['corrects']['test'].append(sum(_corrects))\n",
    "    results['accs']['test'].append(accs)  \n",
    "\n",
    "    es_queue.append(results['losses']['val'][-1])\n",
    "    if len(es_queue) >= es_size:\n",
    "        if (np.diff(es_queue) >= 0).all() and (np.diff(results['losses']['trn'][-es_size:]) < 0).all():\n",
    "            es_flag = True\n",
    "\n",
    "    print(\"| Epoch %d/%d |\"%(epoch+1, n_epochs), end=' Early stopping!\\n' if es_flag else '\\n')\n",
    "    print(\"| Train      | Loss %6.2f | Acc. %6.2f |\"%(results['losses']['trn'][-1], results['accs']['trn'][-1]))\n",
    "    print(\"| Validation | Loss %6.2f | Acc. %6.2f |\"%(results['losses']['val'][-1], results['accs']['val'][-1]))\n",
    "    print(\"| Test       | Loss %6.2f | Acc. %6.2f |\"%(results['losses']['test'][-1], results['accs']['test'][-1]))\n",
    "\n",
    "    if es_flag:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[10,5])\n",
    "ax = fig.add_subplot(1,2,1)\n",
    "ax.plot(results['losses']['trn'], label='Trn.')\n",
    "ax.plot(results['losses']['val'], label='Val.')\n",
    "ax.plot(results['losses']['test'], label='Test')\n",
    "ax.legend()\n",
    "ax.set_title('Loss')\n",
    "\n",
    "ax = fig.add_subplot(1,2,2)\n",
    "ax.plot(results['accs']['trn'], label='Trn.')\n",
    "ax.plot(results['accs']['val'], label='Val.')\n",
    "ax.plot(results['accs']['test'], label='Test')\n",
    "ax.legend()\n",
    "ax.set_title('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_attention(m):\n",
    "    forward_orig = m.forward\n",
    "\n",
    "    def wrap(*args, **kwargs):\n",
    "        kwargs[\"need_weights\"] = True\n",
    "        kwargs[\"average_attn_weights\"] = False\n",
    "\n",
    "        return forward_orig(*args, **kwargs)\n",
    "\n",
    "    m.forward = wrap\n",
    "attn_layers = []\n",
    "for i in range(len(img_type)):\n",
    "    attn_layers.append(model.attns[i].layers[-1].self_attn)\n",
    "    patch_attention(attn_layers[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_features, attn_inputs, attn_outputs = {_type:[] for _type in img_type}, {_type:[] for _type in img_type}, {_type:[] for _type in img_type}\n",
    "hooks = []\n",
    "for i in range(len(img_type)):\n",
    "  hooks.append(model.vgg16_models[i][-1].register_forward_hook(\n",
    "      lambda self, input, output: vgg16_features.append(output)\n",
    "    ))\n",
    "  hooks.append(attn_layers[i].register_forward_hook(\n",
    "      lambda self, input, output: attn_inputs.append(input[0])\n",
    "    ))\n",
    "  hooks.append(attn_layers[i].register_forward_hook(\n",
    "      lambda self, input, output: attn_outputs.append(output)\n",
    "    ))\n",
    "\n",
    "# # propagate through the model\n",
    "# outputs = model(x)\n",
    "\n",
    "# for hook in hooks:\n",
    "#     hook.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 130\n",
    "img = dataset_test.dataset['images'][idx:idx+1].to(device)\n",
    "score = dataset_test.dataset['scores'][idx:idx+1]\n",
    "label = dataset_test.dataset['labels'][idx:idx+1]\n",
    "print(img.shape, score, label)\n",
    "\n",
    "y_pred = model(img)\n",
    "# Grad-CAM\n",
    "# class_idx = y_pred.argmax(-1).item()\n",
    "# heatmap = model.generate_cam(img, class_idx).cpu()\n",
    "# print(heatmap.shape)\n",
    "\n",
    "# Self-attention\n",
    "for hook in hooks:\n",
    "    hook.remove()\n",
    "B,C,H,W = vgg16_features[0].shape\n",
    "attn_weights = attn_outputs[0][1]\n",
    "heatmap = attn_weights[:,0,0,1:].reshape(B,H,W).detach().cpu()\n",
    "heatmap = torch.clamp(heatmap, min=0)\n",
    "heatmap /= heatmap.max()\n",
    "\n",
    "heatmap = np.uint8(255 * heatmap)\n",
    "heatmap = np.uint8(Image.fromarray(heatmap[0]).resize((img.shape[2], img.shape[3])))\n",
    "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "print(heatmap.shape)\n",
    "\n",
    "# alpha = 1.0\n",
    "# superimposed_img = heatmap * alpha #+ img[0].permute(1,2,0).detach().cpu().numpy()\n",
    "# superimposed_img = np.clip(superimposed_img, 0, 255).astype(np.uint8)\n",
    "\n",
    "plt.imshow(img[0].detach().cpu().permute(1,2,0))\n",
    "plt.imshow(heatmap, alpha=0.5)\n",
    "plt.colorbar()\n",
    "plt.axis('off')\n",
    "plt.title('Pred: %d vs. GT: %d'%(y_pred.argmax(-1).item(), label.item()))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cdt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
