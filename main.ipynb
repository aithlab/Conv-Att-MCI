{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import Conv_Att_MCI_Dataset\n",
    "from models import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "n_epochs = 100\n",
    "\n",
    "#optimizer\n",
    "lr = 1e-5\n",
    "beta_1 = 0.9\n",
    "beta_2 = 0.99\n",
    "eps = 1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Conv_Att_MCI_Dataset()\n",
    "dataset_trn, dataset_val, dataset_test = dataset.split_trn_val_test()\n",
    "dataloader_trn = DataLoader(dataset_trn, batch_size=batch_size, shuffle=True)\n",
    "dataloader_val = DataLoader(dataset_val, batch_size=batch_size, shuffle=True)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base = BaseModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model_base.parameters(), lr, [beta_1, beta_2], eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    'losses':{'trn':[], 'val':[], 'test':[]},\n",
    "    'corrects':{'trn':[], 'val':[], 'test':[]},\n",
    "    'accs':{'trn':[], 'val':[], 'test':[]},\n",
    "}\n",
    "for epoch in range(n_epochs):\n",
    "    _losses, _corrects, n_tot = [],[],0\n",
    "    for x, y, info in dataloader_trn:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        y_pred = model_base(x)\n",
    "        y_prob = y_pred.softmax(-1)[:,1]\n",
    "        loss = F.binary_cross_entropy(y_prob, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _correct = ((y_prob >= 0.5) == info['labels']).sum()\n",
    "\n",
    "        _losses.append(loss.item())\n",
    "        _corrects.append(_correct)\n",
    "        n_tot += len(x)\n",
    "    \n",
    "    accs = sum(_corrects) / n_tot\n",
    "    results['losses']['trn'].append(np.mean(_losses))\n",
    "    results['corrects']['trn'].append(sum(_corrects))\n",
    "    results['accs']['trn'].append(accs)\n",
    "\n",
    "    _losses, _corrects, n_tot = [],[],0\n",
    "    for x, y, info in dataloader_val:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        y_pred = model_base(x)\n",
    "        y_prob = y_pred.softmax(-1)[:,1]\n",
    "        loss = F.binary_cross_entropy(y_prob, y)\n",
    "\n",
    "        _correct = ((y_prob >= 0.5) == info['labels']).sum()\n",
    "\n",
    "        _losses.append(loss.item())\n",
    "        _corrects.append(_correct)\n",
    "        n_tot += len(x)\n",
    "    \n",
    "    accs = sum(_corrects) / n_tot\n",
    "    results['losses']['val'].append(np.mean(_losses))\n",
    "    results['corrects']['val'].append(sum(_corrects))\n",
    "    results['accs']['val'].append(accs)\n",
    "\n",
    "    _losses, _corrects, n_tot = [],[],0\n",
    "    for x, y, info in dataloader_test:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        y_pred = model_base(x)\n",
    "        y_prob = y_pred.softmax(-1)[:,1]\n",
    "        loss = F.binary_cross_entropy(y_prob, y)\n",
    "\n",
    "        _correct = ((y_prob >= 0.5) == info['labels']).sum()\n",
    "\n",
    "        _losses.append(loss.item())\n",
    "        _corrects.append(_correct)\n",
    "        n_tot += len(x)\n",
    "    \n",
    "    accs = sum(_corrects) / n_tot\n",
    "    results['losses']['test'].append(np.mean(_losses))\n",
    "    results['corrects']['test'].append(sum(_corrects))\n",
    "    results['accs']['test'].append(accs)  \n",
    "\n",
    "    print(\"| Epoch %d/%d |\"%(epoch+1, n_epochs))\n",
    "    print(\"| Train      | Loss %6.2f | Acc. %6.2f |\"%(results['losses']['trn'][-1], results['accs']['trn'][-1]))\n",
    "    print(\"| Validation | Loss %6.2f | Acc. %6.2f |\"%(results['losses']['val'][-1], results['accs']['val'][-1]))\n",
    "    print(\"| Test       | Loss %6.2f | Acc. %6.2f |\"%(results['losses']['test'][-1], results['accs']['test'][-1]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cdt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
