{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = '/Users/taehwan/Documents/Dataset/Research/MCI-multiple-drawings-main/'\n",
    "image_folder = os.path.join(DATASET_DIR, 'images')\n",
    "info_path = os.path.join(DATASET_DIR, 'label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>MoCA_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>183192446897344463</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>709826307947687256</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5369451065768846145</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1143689677293719381</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4411317949961185459</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>7109828357769709390</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>2329050542067005133</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>4531882259118874201</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>2095518054555003585</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>4612900631321837129</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>918 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              patient_id  MoCA_score\n",
       "0     183192446897344463          26\n",
       "1     709826307947687256          27\n",
       "2    5369451065768846145          29\n",
       "3    1143689677293719381          22\n",
       "4    4411317949961185459          28\n",
       "..                   ...         ...\n",
       "913  7109828357769709390          21\n",
       "914  2329050542067005133          20\n",
       "915  4531882259118874201          28\n",
       "916  2095518054555003585          26\n",
       "917  4612900631321837129          25\n",
       "\n",
       "[918 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info = pd.read_csv(info_path)\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {}\n",
    "for patient_id in os.listdir(image_folder):\n",
    "    if not patient_id.isdigit():\n",
    "        continue\n",
    "    _patient_folder = os.path.join(image_folder, patient_id)\n",
    "    image_paths = [os.path.join(_patient_folder, img_file) for img_file in os.listdir(_patient_folder) if os.path.splitext(img_file)[-1] == '.png']\n",
    "    \n",
    "    mask_patient = info['patient_id'] == int(patient_id)\n",
    "    assert sum(mask_patient) == 1\n",
    "    moca_score = info[mask_patient]['MoCA_score'].iloc[0]\n",
    "    \n",
    "    dataset[int(patient_id)] = {os.path.basename(_path).split('.')[0]:_path for _path in image_paths}\n",
    "    dataset[int(patient_id)]['score'] = moca_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# As Dataset for PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from copy import deepcopy\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = '/Users/taehwan/Documents/Dataset/Research/MCI-multiple-drawings-main/'\n",
    "\n",
    "class Conv_Att_MCI_Dataset(Dataset):\n",
    "    def __init__(self, img_type='all'):\n",
    "        self.dataset_raw = self.load_dataset()\n",
    "        self.load_images(img_type)\n",
    "\n",
    "    def load_dataset(self):\n",
    "        image_folder = os.path.join(DATASET_DIR, 'images')\n",
    "        info_path = os.path.join(DATASET_DIR, 'label.csv')\n",
    "        info = pd.read_csv(info_path)\n",
    "\n",
    "        dataset = {}\n",
    "        for patient_id in os.listdir(image_folder):\n",
    "            if not patient_id.isdigit():\n",
    "                continue\n",
    "            _patient_folder = os.path.join(image_folder, patient_id)\n",
    "            image_paths = [os.path.join(_patient_folder, img_file) for img_file in os.listdir(_patient_folder) if os.path.splitext(img_file)[-1] == '.png']\n",
    "            \n",
    "            mask_patient = info['patient_id'] == int(patient_id)\n",
    "            assert sum(mask_patient) == 1\n",
    "            moca_score = info[mask_patient]['MoCA_score'].iloc[0]\n",
    "            \n",
    "            dataset[int(patient_id)] = {os.path.basename(_path).split('.')[0]:_path for _path in image_paths}\n",
    "            dataset[int(patient_id)]['score'] = moca_score\n",
    "        return dataset\n",
    "\n",
    "    def load_images(self, img_type):\n",
    "        img_type = ['clock', 'trail', 'copy'] if img_type == 'all' else [img_type]\n",
    "\n",
    "        transform_aug = transforms.Compose([\n",
    "            transforms.Pad([12,12,12,12]), # left, top, right, bottom\n",
    "            transforms.RandomCrop([256,256])\n",
    "        ])\n",
    "\n",
    "        transform = transforms.Compose([\n",
    "                    transforms.ToTensor()\n",
    "                ])\n",
    "\n",
    "        for patient_id in self.dataset_raw:\n",
    "            for _type in img_type:\n",
    "                _img_path = self.dataset_raw[patient_id][_type]\n",
    "                _img = Image.open(_img_path)\n",
    "                assert _img.size == (256,256)\n",
    "                _img_aug = _img.copy()\n",
    "\n",
    "                img = transform(_img)\n",
    "                img_aug = transform(transform_aug(_img_aug))\n",
    "\n",
    "                self.dataset_raw[patient_id]['images'] = {'original': img, 'augmented':img_aug}\n",
    "    \n",
    "    def make_dataset(self):\n",
    "        images, images_aug, labels, scores = [],[],[],[]\n",
    "        for patient_id in self.dataset_raw:\n",
    "            _img = self.dataset_raw[patient_id]['images']['original']\n",
    "            _img_aug = self.dataset_raw[patient_id]['images']['augmented']\n",
    "            _score = self.dataset_raw[patient_id]['score']\n",
    "            images.append(_img)\n",
    "            images_aug.append(_img_aug)\n",
    "            scores.append(_score)\n",
    "            labels.append(_score < 25)\n",
    "        dataset = {'images':torch.stack(images), \n",
    "                   'images_aug':torch.stack(images_aug),\n",
    "                   'scores':torch.Tensor(scores),\n",
    "                   'labels':torch.Tensor(labels)}\n",
    "        n_tot = len(dataset['images'])\n",
    "        assert n_tot == len(dataset['images_aug']) == len(dataset['scores']) == len(dataset['labels']), \"%d %s %s %s\"%(n_tot, dataset['images_aug'].shape, dataset['scores'].shape, dataset['labels'].shape)\n",
    "        return dataset, n_tot\n",
    "    \n",
    "    def random_select_idxs(self, idxs, n):\n",
    "        idxs_idxs_selected = np.random.choice(len(idxs), n, replace=False)\n",
    "        idxs_selected = idxs[idxs_idxs_selected]\n",
    "        idxs = np.delete(idxs, idxs_idxs_selected)\n",
    "        return idxs, idxs_selected\n",
    "    \n",
    "    def split_trn_val_test(self, prob=[0.7,0.15,0.15]): #prob=[trn, val, test]\n",
    "        _dataset, n_tot = self.make_dataset()\n",
    "        \n",
    "        # for test\n",
    "        _dataset['images'] = torch.arange(len(_dataset['images'])) \n",
    "        _dataset['images_aug'] = torch.arange(len(_dataset['images_aug'])) + len(_dataset['images'])\n",
    "\n",
    "        n_labels = len(_dataset['labels'].unique())\n",
    "\n",
    "        idxs_per_class = {}\n",
    "        for _class in range(n_labels):\n",
    "            _idxs = torch.where(_dataset['labels']==_class)[0]\n",
    "            idxs_per_class[_class] = _idxs\n",
    "\n",
    "        dataset = {'trn':{k:[]for k in _dataset.keys()}, \n",
    "                'test':{k:[]for k in _dataset.keys()}, \n",
    "                'val':{k:[]for k in _dataset.keys()}}\n",
    "\n",
    "        for _class, _idxs in idxs_per_class.items():\n",
    "            n_tot = len(_idxs)\n",
    "            n_trn, n_test = round(n_tot*prob[0]), round(n_tot*prob[-1])\n",
    "            n_val = n_tot - (n_trn+n_test)\n",
    "            _idxs, idxs_trn = self.random_select_idxs(_idxs, n_trn)\n",
    "            _idxs, idxs_val = self.random_select_idxs(_idxs, n_val)\n",
    "            _idxs, idxs_test = self.random_select_idxs(_idxs, n_test)\n",
    "            assert len(_idxs) == 0\n",
    "            \n",
    "            for k,v in _dataset.items():\n",
    "                dataset['trn'][k].append(v[idxs_trn])\n",
    "                dataset['val'][k].append(v[idxs_val])\n",
    "                dataset['test'][k].append(v[idxs_test])\n",
    "\n",
    "        for _type in dataset:\n",
    "            for k in dataset[_type]:\n",
    "                dataset[_type][k] = torch.cat(dataset[_type][k])\n",
    "\n",
    "        return self._split(dataset['trn']), self._split(dataset['val']), self._split(dataset['test'])\n",
    "\n",
    "    def _split(self, _dataset):\n",
    "        soft_label = self.get_soft_label(_dataset['scores'])\n",
    "        self.dataset = {\n",
    "            'images':torch.cat([_dataset['images'], _dataset['images_aug']]),\n",
    "            'labels':torch.cat([_dataset['labels'], _dataset['labels']]),\n",
    "            'scores':torch.cat([soft_label, soft_label])\n",
    "        }\n",
    "        return deepcopy(self)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset['labels'])\n",
    "    \n",
    "    def get_soft_label(self, scores):\n",
    "        return 1 - torch.sigmoid(scores - 24.5)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        images = self.dataset['images'][idx]\n",
    "        scores = self.dataset['scores'][idx]\n",
    "        labels = self.dataset['labels'][idx]\n",
    "        return images, scores, {'labels':labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Conv_Att_MCI_Dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/72/49hjh1z938b6j84b5pj_rln00000gn/T/ipykernel_80723/464125412.py:65: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  'labels':torch.Tensor(labels)}\n"
     ]
    }
   ],
   "source": [
    "dataset_trn, dataset_val, dataset_test = dataset.split_trn_val_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_trn = DataLoader(dataset_trn, batch_size=64, shuffle=True)\n",
    "dataloader_val = DataLoader(dataset_val, batch_size=64, shuffle=True)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trn, data_val, data_test = [],[],[]\n",
    "for data, label, _ in dataloader_trn:\n",
    "    data_trn.append(data)\n",
    "for data, label, _ in dataloader_val:\n",
    "    data_val.append(data)\n",
    "for data, label, _ in dataloader_test:\n",
    "    data_test.append(data)\n",
    "\n",
    "data_trn = torch.cat(data_trn)\n",
    "data_val = torch.cat(data_val)\n",
    "data_test = torch.cat(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1286, 274, 276, 1836)"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_trn), len(data_val), len(data_test), 1286+274+276"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1836"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(torch.cat([data_trn,data_val,data_test]).unique())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cdt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
